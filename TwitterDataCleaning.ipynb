{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop words / Function words removing.\n",
    "\n",
    "Data input :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43140\n",
      "19468\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>tweet</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>place</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sun Dec 06 12:29:32 +0000 2015</td>\n",
       "      <td>Actor Morgan Freeman unhurt after plane's forc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sun Dec 06 12:29:32 +0000 2015</td>\n",
       "      <td>#YouAintNoMuslimBruv London Pride</td>\n",
       "      <td>YouAintNoMuslimBruv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sun Dec 06 12:29:32 +0000 2015</td>\n",
       "      <td>Breaking News:The second  message of The Supre...</td>\n",
       "      <td>YouCanDoItLiam PlaylistE1 CABASM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sun Dec 06 12:29:32 +0000 2015</td>\n",
       "      <td>#MTVStars One Direction https://t.co/QAUgm4aaEN</td>\n",
       "      <td>MTVStars</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sun Dec 06 12:29:32 +0000 2015</td>\n",
       "      <td>@sanjaymanjrekar Fascinating to watch @amlahas...</td>\n",
       "      <td>IndvsSA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             time  \\\n",
       "0  Sun Dec 06 12:29:32 +0000 2015   \n",
       "6  Sun Dec 06 12:29:32 +0000 2015   \n",
       "7  Sun Dec 06 12:29:32 +0000 2015   \n",
       "8  Sun Dec 06 12:29:32 +0000 2015   \n",
       "9  Sun Dec 06 12:29:32 +0000 2015   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  Actor Morgan Freeman unhurt after plane's forc...   \n",
       "6                  #YouAintNoMuslimBruv London Pride   \n",
       "7  Breaking News:The second  message of The Supre...   \n",
       "8    #MTVStars One Direction https://t.co/QAUgm4aaEN   \n",
       "9  @sanjaymanjrekar Fascinating to watch @amlahas...   \n",
       "\n",
       "                           hashtags place  location  \n",
       "0                               NaN   NaN       NaN  \n",
       "6               YouAintNoMuslimBruv   NaN       NaN  \n",
       "7  YouCanDoItLiam PlaylistE1 CABASM   NaN       NaN  \n",
       "8                          MTVStars   NaN       NaN  \n",
       "9                           IndvsSA   NaN       NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NorthAmerica = pd.read_csv(\"rawdata/trends/1206/NorthAmerica_Trends1206.csv\",sep = \",\", header = 0)\n",
    "\n",
    "#NorthAmerica.columns = ['time','tweet','hashtags','location']\n",
    "NorthAmerica.columns = ['time','tweet','hashtags','place', 'location']\n",
    "print len(NorthAmerica.index)\n",
    "NorthAmerica = NorthAmerica.drop_duplicates(subset='tweet',keep='last') #remove the duplicate tweets\n",
    "print len(NorthAmerica.index)\n",
    "\n",
    "\n",
    "TwitterData = NorthAmerica\n",
    "TwitterData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning, Tokenization and Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove stopwords :\n",
    "\n",
    "we define a function for cleaning the tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#stemming\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "#from __future__ import print_function, unicode_literals\n",
    "# Create p_stemmer of class PorterStemmer\n",
    "s_stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "def filter_tweet (sample):\n",
    "    stopped_tokens = [re.sub(r'(^https?:\\/\\/.*[\\r\\n]*)|(@[A-Za-z0-9]+)|(#[A-Za-z0-9]+)|(\\n)|([^\\w])|(RT)',\n",
    "                '', word, flags=re.MULTILINE) for word in sample.split(\" \") if word not in stopwords.words('english')] \n",
    "    filtered_sample = filter(None,stopped_tokens)\n",
    "    filtered_sample = [s_stemmer.stem(i).lower() for i in filtered_sample] \n",
    "    #filtered_sample = [s_stemmer(i.lower()) for i in filtered_sample]\n",
    "    filtered_sample = \" \".join(filtered_sample)\n",
    "    return filtered_sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the List of tweets :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ListTweets = [filter_tweet(tweet) for tweet in TwitterData.tweet.values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test by sampling :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I got a warm feeling with zayn's rt #ZaynsStill1DAF\n",
      "\n",
      "\n",
      "i got warm feel zayn rt\n"
     ]
    }
   ],
   "source": [
    "#sample\n",
    "sample_index = 5\n",
    "print TwitterData.tweet.values[sample_index]+\"\\n\\n\"\n",
    "print ListTweets[sample_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liam payn babi i am so so proud of youyou this we know can and stumbl well you\n",
      "LIAM PAYNE BABY I AM SO SO PROUD OF YOU...you can do this, We all know you can. And if you stumble, we'll all be here for you#YouCanDoItLiam\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print filter_tweet(TwitterData.tweet.values[115])\n",
    "print TwitterData.tweet.values[115]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lower for hashtags\n",
    "ListHashtags =[str(hashtag).lower() for hashtag in TwitterData.hashtags.values]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the cleaned data to a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TwitterData_cleaned = pd.DataFrame({\"tweet\": ListTweets, \n",
    "                                   \"hashtags\": ListHashtags,\n",
    "                                   \"location\": TwitterData.location})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TwitterData_cleaned.to_csv(\"predata/NorthAmerica_Trends_cleaned.csv\", sep = \",\", header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtags</th>\n",
       "      <th>location</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>actor morgan freeman unhurt plane forc land</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>youaintnomuslimbruv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>london pride</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>youcandoitliam playliste1 cabasm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>break newsth second messag the suprem leadersa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mtvstars</td>\n",
       "      <td>NaN</td>\n",
       "      <td>one direct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>indvssa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fascin watch amp even thoughenough variat bowler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>zaynsstill1daf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i got warm feel zayn rt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>break news the second letter islam revolut leader</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>_scout look like south carolina get thir 6th 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>youcandoitliam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>_liam_payn well know easi youin good time bad ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>youaintnomuslimbruv youaintnopatriot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>post divis propaganda aid isil caus real briti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                hashtags  location  \\\n",
       "0                                    nan       NaN   \n",
       "6                    youaintnomuslimbruv       NaN   \n",
       "7       youcandoitliam playliste1 cabasm       NaN   \n",
       "8                               mtvstars       NaN   \n",
       "9                                indvssa       NaN   \n",
       "12                        zaynsstill1daf       NaN   \n",
       "14                                   nan       NaN   \n",
       "16                                   nan       NaN   \n",
       "17                        youcandoitliam       NaN   \n",
       "18  youaintnomuslimbruv youaintnopatriot       NaN   \n",
       "\n",
       "                                                tweet  \n",
       "0         actor morgan freeman unhurt plane forc land  \n",
       "6                                        london pride  \n",
       "7   break newsth second messag the suprem leadersa...  \n",
       "8                                          one direct  \n",
       "9    fascin watch amp even thoughenough variat bowler  \n",
       "12                            i got warm feel zayn rt  \n",
       "14  break news the second letter islam revolut leader  \n",
       "16  _scout look like south carolina get thir 6th 7...  \n",
       "17  _liam_payn well know easi youin good time bad ...  \n",
       "18  post divis propaganda aid isil caus real briti...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TwitterData_cleaned[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Trends Pre-processing \n",
    "\n",
    "We will save two pandas.dataframe to store the 'keywords' and 'hashtags' seprately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>createdAt</th>\n",
       "      <th>trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-12-06T12:21:40Z</td>\n",
       "      <td>Ayesha Curry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-12-06T12:21:40Z</td>\n",
       "      <td>#YouCanDoItLiam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-12-06T12:21:40Z</td>\n",
       "      <td>#LosDeChavezAVotar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-12-06T12:21:40Z</td>\n",
       "      <td>#6DCambiemosVzla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-12-06T12:21:40Z</td>\n",
       "      <td>#WetMusic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              createdAt               trend\n",
       "0  2015-12-06T12:21:40Z        Ayesha Curry\n",
       "1  2015-12-06T12:21:40Z     #YouCanDoItLiam\n",
       "2  2015-12-06T12:21:40Z  #LosDeChavezAVotar\n",
       "3  2015-12-06T12:21:40Z    #6DCambiemosVzla\n",
       "4  2015-12-06T12:21:40Z           #WetMusic"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Trends = pd.read_csv(\"rawdata/trends/1206/Trends1206.csv\",sep = \",\", header = 0)\n",
    "\n",
    "Trends.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ayesha curry',\n",
       " '#youcandoitliam',\n",
       " '#losdechavezavotar',\n",
       " '#6dcambiemosvzla',\n",
       " '#wetmusic',\n",
       " '#youaintnomuslimbruv',\n",
       " 'jim ross',\n",
       " 'good sunday',\n",
       " 'aden',\n",
       " 'ysabel']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ListTrends =[str(hashtag).lower() for hashtag in Trends.trend.values]\n",
    "ListTrends[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>felizdomingo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>reenergise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>onepiece</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>iotwf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ptxinsf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         hashtag\n",
       "10  felizdomingo\n",
       "13    reenergise\n",
       "14      onepiece\n",
       "18         iotwf\n",
       "23       ptxinsf"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hashtags_cleaned = pd.DataFrame({\"hashtag\": [word[1:] for word in ListTrends if \"#\" in word]})\n",
    "Hashtags_cleaned = Hashtags_cleaned.drop_duplicates(subset='hashtag',keep='last')\n",
    "print len(Hashtags_cleaned)\n",
    "Hashtags_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ysabel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>morgan freeman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>todos a votar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>archie griffin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>nelena</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           keyword\n",
       "4           ysabel\n",
       "7   morgan freeman\n",
       "8    todos a votar\n",
       "9   archie griffin\n",
       "11          nelena"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Keywords_cleaned = pd.DataFrame({\"keyword\": [word for word in ListTrends if \"#\" not in word]})\n",
    "Keywords_cleaned = Keywords_cleaned.drop_duplicates(subset='keyword',keep='last')\n",
    "print len(Keywords_cleaned)\n",
    "Keywords_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Hashtags_cleaned.to_csv(\"predata/Hashtags_cleaned1206.csv\", sep = \",\", header = True, index = False)\n",
    "Keywords_cleaned.to_csv(\"predata/Keywords_cleaned1206.csv\", sep = \",\", header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
