{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop words / Function words removing.\n",
    "\n",
    "Data input :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64817\n",
      "30268\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>tweet</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>place</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sat Dec 05 02:00:59 +0000 2015</td>\n",
       "      <td>Zack Greinke Inks 6 Year Deal With ArizonaDiam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sat Dec 05 02:00:59 +0000 2015</td>\n",
       "      <td>Reporters Allowed in Home of Shooting Suspects...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sat Dec 05 02:00:59 +0000 2015</td>\n",
       "      <td>iMessage just autocorrected Greinke to Grinch ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sat Dec 05 02:00:59 +0000 2015</td>\n",
       "      <td>I might be the only person that doesn't care t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sat Dec 05 02:00:59 +0000 2015</td>\n",
       "      <td>Killers deserve no respect!  https://t.co/c5q0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              time  \\\n",
       "1   Sat Dec 05 02:00:59 +0000 2015   \n",
       "2   Sat Dec 05 02:00:59 +0000 2015   \n",
       "8   Sat Dec 05 02:00:59 +0000 2015   \n",
       "10  Sat Dec 05 02:00:59 +0000 2015   \n",
       "12  Sat Dec 05 02:00:59 +0000 2015   \n",
       "\n",
       "                                                tweet hashtags        place  \\\n",
       "1   Zack Greinke Inks 6 Year Deal With ArizonaDiam...      NaN          NaN   \n",
       "2   Reporters Allowed in Home of Shooting Suspects...      NaN          NaN   \n",
       "8   iMessage just autocorrected Greinke to Grinch ...      NaN  Los Angeles   \n",
       "10  I might be the only person that doesn't care t...      NaN          NaN   \n",
       "12  Killers deserve no respect!  https://t.co/c5q0...      NaN          NaN   \n",
       "\n",
       "   location  \n",
       "1       NaN  \n",
       "2       NaN  \n",
       "8       NaN  \n",
       "10      NaN  \n",
       "12      NaN  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NorthAmerica = pd.read_csv(\"rawdata/NorthAmerica_Trends.csv\",sep = \",\", header = 0)\n",
    "\n",
    "#NorthAmerica.columns = ['time','tweet','hashtags','location']\n",
    "NorthAmerica.columns = ['time','tweet','hashtags','place', 'location']\n",
    "print len(NorthAmerica.index)\n",
    "NorthAmerica = NorthAmerica.drop_duplicates(subset='tweet',keep='last') #remove the duplicate tweets\n",
    "print len(NorthAmerica.index)\n",
    "\n",
    "\n",
    "TwitterData = NorthAmerica\n",
    "TwitterData.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning, Tokenization and Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove stopwords :\n",
    "\n",
    "we define a function for cleaning the tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#stemming\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "#from __future__ import print_function, unicode_literals\n",
    "# Create p_stemmer of class PorterStemmer\n",
    "s_stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "def filter_tweet (sample):\n",
    "    stopped_tokens = [re.sub(r'(^https?:\\/\\/.*[\\r\\n]*)|(@[A-Za-z0-9]+)|(#[A-Za-z0-9]+)|(\\n)|([^\\w])|(RT)',\n",
    "                '', word, flags=re.MULTILINE) for word in sample.split(\" \") if word not in stopwords.words('english')] \n",
    "    filtered_sample = filter(None,stopped_tokens)\n",
    "    filtered_sample = [s_stemmer.stem(i).lower() for i in filtered_sample] \n",
    "    #filtered_sample = [s_stemmer(i.lower()) for i in filtered_sample]\n",
    "    filtered_sample = \" \".join(filtered_sample)\n",
    "    return filtered_sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the List of tweets :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ListTweets = [filter_tweet(tweet) for tweet in TwitterData.tweet.values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test by sampling :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @PoliticalGroove: The GOP vs women's right to their own bodies #TotallyAbsurdWars\n",
      "\n",
      "\n",
      "the gop vs women right bodi\n"
     ]
    }
   ],
   "source": [
    "#sample\n",
    "sample_index = 5\n",
    "print TwitterData.tweet.values[sample_index]+\"\\n\\n\"\n",
    "print ListTweets[sample_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best potus gif ever ht\n",
      "RT @EricWolfson: BEST. POTUS. GIF. EVER.\r\n",
      "#NationalCookieDay\r\n",
      "\r\n",
      "RT @BuzzFeed #ThanksObama\r\n",
      "https://t.co/efst1XcehU || h/t @TheObamaDiary #p2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print filter_tweet(TwitterData.tweet.values[115])\n",
    "print TwitterData.tweet.values[115]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lower for hashtags\n",
    "ListHashtags =[str(hashtag).lower() for hashtag in TwitterData.hashtags.values]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the cleaned data to a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TwitterData_cleaned = pd.DataFrame({\"tweet\": ListTweets, \n",
    "                                   \"hashtags\": ListHashtags,\n",
    "                                   \"location\": TwitterData.location})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TwitterData_cleaned.to_csv(\"cleaned data/NorthAmerica_Trends_cleaned.csv\", sep = \",\", header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtags</th>\n",
       "      <th>location</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zack greink ink 6 year deal with arizonadiamon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>report allow home shoot suspect media crew got...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>imessag autocorrect greink grinch first time e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i might person doesnt care scott weiland die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>killer deserv respect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>totallyabsurdwars</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the gop vs women right bodi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>artbasel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s biggest boldest best moment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dbacks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>greink age 32 go make 343 million annual 6 yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>theexperience10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>this lord wow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>dothan alabama drugs war huntsville</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cop plant anoth reason 2 end drug https</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               hashtags location  \\\n",
       "1                                   nan      NaN   \n",
       "2                                   nan      NaN   \n",
       "8                                   nan      NaN   \n",
       "10                                  nan      NaN   \n",
       "12                                  nan      NaN   \n",
       "13                    totallyabsurdwars      NaN   \n",
       "14                             artbasel      NaN   \n",
       "15                               dbacks      NaN   \n",
       "17                      theexperience10      NaN   \n",
       "18  dothan alabama drugs war huntsville      NaN   \n",
       "\n",
       "                                                tweet  \n",
       "1   zack greink ink 6 year deal with arizonadiamon...  \n",
       "2   report allow home shoot suspect media crew got...  \n",
       "8   imessag autocorrect greink grinch first time e...  \n",
       "10       i might person doesnt care scott weiland die  \n",
       "12                              killer deserv respect  \n",
       "13                        the gop vs women right bodi  \n",
       "14                      s biggest boldest best moment  \n",
       "15  greink age 32 go make 343 million annual 6 yea...  \n",
       "17                                      this lord wow  \n",
       "18            cop plant anoth reason 2 end drug https  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TwitterData_cleaned[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Trends Pre-processing \n",
    "\n",
    "We will save two pandas.dataframe to store the 'keywords' and 'hashtags' seprately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>createdAt</th>\n",
       "      <th>trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-12-05T02:14:57Z</td>\n",
       "      <td>Greinke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-12-05T02:14:57Z</td>\n",
       "      <td>#TwitterAwakens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-12-05T02:14:57Z</td>\n",
       "      <td>#BlueNeighbourhood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-12-05T02:14:57Z</td>\n",
       "      <td>Robert Loggia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-12-05T02:14:57Z</td>\n",
       "      <td>#RDFamilyHoliday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              createdAt               trend\n",
       "0  2015-12-05T02:14:57Z             Greinke\n",
       "1  2015-12-05T02:14:57Z     #TwitterAwakens\n",
       "2  2015-12-05T02:14:57Z  #BlueNeighbourhood\n",
       "3  2015-12-05T02:14:57Z       Robert Loggia\n",
       "4  2015-12-05T02:14:57Z    #RDFamilyHoliday"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Trends = pd.read_csv(\"rawdata/Trends.csv\",sep = \",\", header = 0)\n",
    "\n",
    "Trends.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['greinke',\n",
       " '#twitterawakens',\n",
       " '#blueneighbourhood',\n",
       " 'robert loggia',\n",
       " '#rdfamilyholiday',\n",
       " '#undateablelive',\n",
       " 'dodgers',\n",
       " '#antm',\n",
       " 'diamondbacks',\n",
       " 'joe johnson']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ListTrends =[str(hashtag).lower() for hashtag in Trends.trend.values]\n",
    "ListTrends[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>engagechat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>twitterawakens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>rdfamilyholiday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>blueneighbourhood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>antm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              hashtag\n",
       "55         engagechat\n",
       "85     twitterawakens\n",
       "86    rdfamilyholiday\n",
       "87  blueneighbourhood\n",
       "88               antm"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hashtags_cleaned = pd.DataFrame({\"hashtag\": [word[1:] for word in ListTrends if \"#\" in word]})\n",
    "Hashtags_cleaned = Hashtags_cleaned.drop_duplicates(subset='hashtag',keep='last')\n",
    "print len(Hashtags_cleaned)\n",
    "Hashtags_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>tom holmoe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>trend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>greinke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>robert loggia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>dodgers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          keyword\n",
       "43     tom holmoe\n",
       "66          trend\n",
       "67        greinke\n",
       "68  robert loggia\n",
       "69        dodgers"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Keywords_cleaned = pd.DataFrame({\"keyword\": [word for word in ListTrends if \"#\" not in word]})\n",
    "Keywords_cleaned = Keywords_cleaned.drop_duplicates(subset='keyword',keep='last')\n",
    "print len(Keywords_cleaned)\n",
    "Keywords_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Hashtags_cleaned.to_csv(\"cleaned data/Hashtags_cleaned1205.csv\", sep = \",\", header = True, index = False)\n",
    "Keywords_cleaned.to_csv(\"cleaned data/Keywords_cleaned1205.csv\", sep = \",\", header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
