{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import re\n",
    "import lda\n",
    "from gensim import corpora, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop words / Function words removing.\n",
    "\n",
    "Data input :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2753\n",
      "2217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mimi/anaconda/lib/python2.7/site-packages/pandas/util/decorators.py:81: FutureWarning: the 'cols' keyword is deprecated, use 'subset' instead\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>tweet</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>zone</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-11-13 23:59:58</td>\n",
       "      <td>So sad that shit like this has to happen in th...</td>\n",
       "      <td>['prayforparis']</td>\n",
       "      <td>Paris, Ile-de-France,France</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-11-13 23:59:55</td>\n",
       "      <td>\"You haven't yet arrived, but you are closer t...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Paris, Ile-de-France,France</td>\n",
       "      <td>Nashville, TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-11-13 23:59:45</td>\n",
       "      <td>RT @IgnazioMottola: Bars quickly evacuated in ...</td>\n",
       "      <td>['bataclan']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-11-13 23:59:41</td>\n",
       "      <td>Frightened... Too many dead people!</td>\n",
       "      <td>[]</td>\n",
       "      <td>Aulnay-sous-Bois, Ile-de-France,France</td>\n",
       "      <td>London - Reading - Manchester</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-11-13 23:59:31</td>\n",
       "      <td>One of the prettiest pictures I took four week...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Paris, Ile-de-France,France</td>\n",
       "      <td>Glasgow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time                                              tweet  \\\n",
       "0  2015-11-13 23:59:58  So sad that shit like this has to happen in th...   \n",
       "1  2015-11-13 23:59:55  \"You haven't yet arrived, but you are closer t...   \n",
       "2  2015-11-13 23:59:45  RT @IgnazioMottola: Bars quickly evacuated in ...   \n",
       "3  2015-11-13 23:59:41                Frightened... Too many dead people!   \n",
       "4  2015-11-13 23:59:31  One of the prettiest pictures I took four week...   \n",
       "\n",
       "           hashtags                                    zone  \\\n",
       "0  ['prayforparis']             Paris, Ile-de-France,France   \n",
       "1                []             Paris, Ile-de-France,France   \n",
       "2      ['bataclan']                                     NaN   \n",
       "3                []  Aulnay-sous-Bois, Ile-de-France,France   \n",
       "4                []             Paris, Ile-de-France,France   \n",
       "\n",
       "                         location  \n",
       "0                             NaN  \n",
       "1                   Nashville, TN  \n",
       "2                             NaN  \n",
       "3   London - Reading - Manchester  \n",
       "4                         Glasgow  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paris13en = pd.read_csv(\"rawdata/paris13en.csv\",sep = \",\", header = None)\n",
    "\n",
    "paris13en.columns = ['time','tweet','hashtags','zone','location']\n",
    "print len(paris13en.index)\n",
    "paris13en = paris13en.drop_duplicates(cols='tweet',take_last = True) #remove the duplicate tweets\n",
    "print len(paris13en.index)\n",
    "\n",
    "\n",
    "TwitterData = paris13en\n",
    "TwitterData.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove stopwords :\n",
    "\n",
    "we define a function for cleaning the tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def filter_tweet (sample):\n",
    "        \n",
    "    filtered_sample = [re.sub(r'(^https?:\\/\\/.*[\\r\\n]*)|(@[A-Za-z0-9]+)|(#[A-Za-z0-9]+)|(\\n)|([^\\w])|(RT)',\n",
    "                '', word, flags=re.MULTILINE) for word in sample.split(\" \") if word not in stopwords.words('english')]\n",
    "\n",
    "    filtered_sample = filter(None,filtered_sample)\n",
    "    return filtered_sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the List of tweets :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mimi/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:4: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n"
     ]
    }
   ],
   "source": [
    "ListTweets = [filter_tweet(tweet) for tweet in TwitterData.tweet.values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test by sampling :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "See them in real life they trying to bust maneuvers- Rowdy x Rebelâ€¦ https://t.co/MGho9y3sv4\n",
      "\n",
      "\n",
      "['See', 'real', 'life', 'trying', 'bust', 'maneuvers', 'Rowdy', 'x', 'Rebel']\n"
     ]
    }
   ],
   "source": [
    "#sample\n",
    "sample_index = 19\n",
    "print TwitterData.tweet.values[sample_index]+\"\\n\\n\"\n",
    "print ListTweets[sample_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ListHashtags = [(re.sub(r'(\\])|(\\[)|(\\')',\"\", hashtag).split(' ')) for hashtag in TwitterData.hashtags.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['']\n",
      "2217\n",
      "2217\n",
      "['Bars', 'quickly', 'evacuated', 'side', 'street', 'close', 'testimonials', 'atmosphere', 'this']\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "print ListHashtags[8]\n",
    "print len(ListHashtags)\n",
    "print len(ListTweets)\n",
    "\n",
    "print ListTweets[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(ListTweets)\n",
    "corpus = [dictionary.doc2bow(text) for text in ListTweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ldamodel = models.ldamodel.LdaModel(corpus, num_topics=100, id2word = dictionary, passes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = ldamodel.print_topics(num_topics=100, num_words=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
